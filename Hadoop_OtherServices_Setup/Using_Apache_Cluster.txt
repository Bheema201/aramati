--Temporary file only for authorized da desktop users

For lab setup in dadesktop..

Start ur machines..

Start Terminal

$sudo su
$cd
$virtualbox

--Start ur machines, c1,c2,c3

Note** make sure you are logged in as 'hdu'
on c1:
cd /usr/local/hadoop

$sbin/start-dfs.sh

on c2:
cd /usr/local/hadoop
$sbin/start-yarn.sh

Now on c1:
ssh c2  & then ssh c3

--You should be in c3 now> (if yes)
<type>
jps
[shows processes running]
<type>
logout
--You should be in c2 now>(if yes)
<type>
jps
[shows processes running]
<type>
logout
--You should be in c1 now>(if yes)
<type>
jps
[shows processes running]
<type>
logout

Access UIs
http://c1:50070
http://c2:8088

To start job history server
on c1:
cd /usr/local/hadoop
sbin/mr-jobhistory-daemon.sh start historyserver

access job history server
http://c1:19888

on c2:
cd /usr/local/spark
sbin/start-history-server.sh

access spark history server: web UI
http://c2:18080

Now access terminal of any machine and try hdfs commands
Make sure you are logged in as 'hdu'
For example:
$hdfs dfs -ls /
